{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.9.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from IPython.display import display, HTML\n",
    "import plotly.graph_objects as go\n",
    "import re\n",
    "# Natural Language Tool Kit\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from collections import Counter\n",
    "import cufflinks as cf\n",
    "\n",
    "cf.go_offline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV file into a dataframe\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "tweets = pd.read_csv(\"tweets.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 4)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([test_df, tweets, train_df],    # Combine vertically\n",
    "                          ignore_index = True,\n",
    "                          sort = False)\n",
    "df = df[['text', 'target']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['earthquake', 'quake', 'temblor', 'seism', 'geological_phenomenon', 'seaquake', 'submarine_earthquake', 'shock', 'seismic_disturbance', 'tremor', 'earth_tremor', 'microseism', 'earthquake', 'disturbance', 'disruption', 'commotion', 'flutter', 'hurly_burly', 'to-do', 'hoo-ha', 'hoo-hah', 'kerfuffle']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "#nltk.download('omw-1.4')\n",
    "\n",
    "related_words = []\n",
    "for syn in wordnet.synsets(\"earthquake\"):\n",
    "    for lemma in syn.lemmas():\n",
    "        related_words.append(lemma.name())\n",
    "    for hyp in syn.hypernyms():\n",
    "        for lemma in hyp.lemmas():\n",
    "            related_words.append(lemma.name())\n",
    "    for hyp in syn.hyponyms():\n",
    "        for lemma in hyp.lemmas():\n",
    "            related_words.append(lemma.name())\n",
    "\n",
    "print(related_words)\n",
    "type(related_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column in the dataset to store whether a tweet is related to an earthquake\n",
    "df[\"earthquake\"] = df[\"text\"].apply(lambda x: any(word in x for word in related_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>earthquake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heard about #earthquake is different cities, stay safe everyone.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                               text  \\\n",
       "0                                                                Just happened a terrible car crash   \n",
       "1                                  Heard about #earthquake is different cities, stay safe everyone.   \n",
       "2  there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all   \n",
       "3                                                          Apocalypse lighting. #Spokane #wildfires   \n",
       "4                                                     Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "\n",
       "   target  earthquake  \n",
       "0     NaN       False  \n",
       "1     NaN        True  \n",
       "2     NaN       False  \n",
       "3     NaN       False  \n",
       "4     NaN       False  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>earthquake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heard about #earthquake is different cities, stay safe everyone.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>We're shaking...It's an earthquake</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Please like and share our new page for our Indoor Trampoline Park Aftershock opening this fall!! http://t.co/UgXhHErrxS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>@bxckylynch foi no ROH Aftershock: Las Vegas procura no pirate bay que tem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Schoolboy ÛÒ Aftershock (Original Mix)\\nExcision &amp;amp; Skism ÛÒ SEXisM (Far Too Loud Remix)\\nFirebeatz Schella ÛÒ Dear New... http://t.co/JQLzUA6YzQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4256</th>\n",
       "      <td>@esskayen Im still in shock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4257</th>\n",
       "      <td>@rhaplord Southern Africa has some buried ancient history that will soon shock mankind</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4258</th>\n",
       "      <td>A 3.1 magnitude #earthquake occured at 141 km SE of Akutan, Alaska. See the full report at: https://t.co/6G96eGwSKY https://t.co/iSZJ2OCMqR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4261</th>\n",
       "      <td>A 2.6 magnitude #earthquake occured at 50 km W of Mentone, Texas. See the full report at: https://t.co/u05byRkaMP https://t.co/kiT02EbgyE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4262</th>\n",
       "      <td>2.6 magnitude #earthquake. 51 km from Mentone, TX, #UnitedStates https://t.co/L8ksM94BE3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>769 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                         text  \\\n",
       "1                                                                                            Heard about #earthquake is different cities, stay safe everyone.   \n",
       "5                                                                                                                          We're shaking...It's an earthquake   \n",
       "44                                    Please like and share our new page for our Indoor Trampoline Park Aftershock opening this fall!! http://t.co/UgXhHErrxS   \n",
       "45                                                                                 @bxckylynch foi no ROH Aftershock: Las Vegas procura no pirate bay que tem   \n",
       "46    Schoolboy ÛÒ Aftershock (Original Mix)\\nExcision &amp; Skism ÛÒ SEXisM (Far Too Loud Remix)\\nFirebeatz Schella ÛÒ Dear New... http://t.co/JQLzUA6YzQ   \n",
       "...                                                                                                                                                       ...   \n",
       "4256                                                                                                                              @esskayen Im still in shock   \n",
       "4257                                                                   @rhaplord Southern Africa has some buried ancient history that will soon shock mankind   \n",
       "4258              A 3.1 magnitude #earthquake occured at 141 km SE of Akutan, Alaska. See the full report at: https://t.co/6G96eGwSKY https://t.co/iSZJ2OCMqR   \n",
       "4261                A 2.6 magnitude #earthquake occured at 50 km W of Mentone, Texas. See the full report at: https://t.co/u05byRkaMP https://t.co/kiT02EbgyE   \n",
       "4262                                                                 2.6 magnitude #earthquake. 51 km from Mentone, TX, #UnitedStates https://t.co/L8ksM94BE3   \n",
       "\n",
       "      target  earthquake  \n",
       "1        NaN        True  \n",
       "5        NaN        True  \n",
       "44       NaN        True  \n",
       "45       NaN        True  \n",
       "46       NaN        True  \n",
       "...      ...         ...  \n",
       "4256     NaN        True  \n",
       "4257     NaN        True  \n",
       "4258     NaN        True  \n",
       "4261     NaN        True  \n",
       "4262     NaN        True  \n",
       "\n",
       "[769 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    11030\n",
       "True       846\n",
       "Name: earthquake, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"earthquake\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with target = 1 or 2 and earthquake = True\n",
    "df_train = df.loc[(df['target'].isin([1])) & (df['earthquake'] == True)]\n",
    "\n",
    "# Create a dataframe with target = NaN and earthquake = False\n",
    "df_test = df.loc[(df['target'].isna()) & (df['earthquake'] == True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>earthquake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heard about #earthquake is different cities, stay safe everyone.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>We're shaking...It's an earthquake</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Please like and share our new page for our Indoor Trampoline Park Aftershock opening this fall!! http://t.co/UgXhHErrxS</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>@bxckylynch foi no ROH Aftershock: Las Vegas procura no pirate bay que tem</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Schoolboy ÛÒ Aftershock (Original Mix)\\nExcision &amp;amp; Skism ÛÒ SEXisM (Far Too Loud Remix)\\nFirebeatz Schella ÛÒ Dear New... http://t.co/JQLzUA6YzQ</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                       text  \\\n",
       "1                                                                                          Heard about #earthquake is different cities, stay safe everyone.   \n",
       "5                                                                                                                        We're shaking...It's an earthquake   \n",
       "44                                  Please like and share our new page for our Indoor Trampoline Park Aftershock opening this fall!! http://t.co/UgXhHErrxS   \n",
       "45                                                                               @bxckylynch foi no ROH Aftershock: Las Vegas procura no pirate bay que tem   \n",
       "46  Schoolboy ÛÒ Aftershock (Original Mix)\\nExcision &amp; Skism ÛÒ SEXisM (Far Too Loud Remix)\\nFirebeatz Schella ÛÒ Dear New... http://t.co/JQLzUA6YzQ   \n",
       "\n",
       "    earthquake  \n",
       "1         True  \n",
       "5         True  \n",
       "44        True  \n",
       "45        True  \n",
       "46        True  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rafaellaporto/opt/anaconda3/lib/python3.9/site-packages/transformers/generation_utils.py:24: FutureWarning:\n",
      "\n",
      "Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "\n",
      "/Users/rafaellaporto/opt/anaconda3/lib/python3.9/site-packages/transformers/generation_tf_utils.py:24: FutureWarning:\n",
      "\n",
      "Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import TFGenerationMixin` instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from transformers import * \n",
    "from tensorflow.keras.layers import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TweetNormalizer\n",
    "From:https://github.com/VinAIResearch/BERTweet/blob/master/TweetNormalizer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#twitter normalizer\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from emoji import demojize\n",
    "import re\n",
    "\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "def normalizeToken(token):\n",
    "    lowercased_token = token.lower()\n",
    "    if token.startswith(\"@\"):\n",
    "        return \"@USER\"\n",
    "    elif lowercased_token.startswith(\"http\") or lowercased_token.startswith(\"www\"):\n",
    "        return \"HTTPURL\"\n",
    "    elif len(token) == 1:\n",
    "        return demojize(token)\n",
    "    else:\n",
    "        if token == \"’\":\n",
    "            return \"'\"\n",
    "        elif token == \"…\":\n",
    "            return \"...\"\n",
    "        else:\n",
    "            return token\n",
    "\n",
    "def normalizeTweet(tweet):\n",
    "    tokens = tokenizer.tokenize(tweet.replace(\"’\", \"'\").replace(\"…\", \"...\"))\n",
    "    normTweet = \" \".join([normalizeToken(token) for token in tokens])\n",
    "\n",
    "    normTweet = normTweet.replace(\"cannot \", \"can not \").replace(\"n't \", \" n't \").replace(\"n 't \", \" n't \").replace(\"ca n't\", \"can't\").replace(\"ai n't\", \"ain't\")\n",
    "    normTweet = normTweet.replace(\"'m \", \" 'm \").replace(\"'re \", \" 're \").replace(\"'s \", \" 's \").replace(\"'ll \", \" 'll \").replace(\"'d \", \" 'd \").replace(\"'ve \", \" 've \")\n",
    "    normTweet = normTweet.replace(\" p . m .\", \"  p.m.\") .replace(\" p . m \", \" p.m \").replace(\" a . m .\", \" a.m.\").replace(\" a . m \", \" a.m \")\n",
    "\n",
    "    normTweet = re.sub(r\",([0-9]{2,4}) , ([0-9]{2,4})\", r\",\\1,\\2\", normTweet)\n",
    "    normTweet = re.sub(r\"([0-9]{1,3}) / ([0-9]{2,4})\", r\"\\1/\\2\", normTweet)\n",
    "    normTweet = re.sub(r\"([0-9]{1,3})- ([0-9]{2,4})\", r\"\\1-\\2\", normTweet)\n",
    "    \n",
    "    return \" \".join(normTweet.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERTweetTokenizer\n",
    "From: https://www.kaggle.com/christofhenkel/setup-tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "from fairseq.data.encoders.fastbpe import fastBPE\n",
    "from fairseq.data import Dictionary\n",
    "\n",
    "\n",
    "class BERTweetTokenizer():\n",
    "    \n",
    "    def __init__(self,pretrained_path):\n",
    "        bpe_dir = os.path.join(pretrained_path,\"bpe.codes\")\n",
    "        vocab_dir = os.path.join(pretrained_path,\"dict.txt\")\n",
    "        \n",
    "        self.bpe = fastBPE(SimpleNamespace(bpe_codes= bpe_dir))\n",
    "        self.vocab = Dictionary()\n",
    "        self.vocab.add_from_file(vocab_dir)\n",
    "        \n",
    "        self.cls_token_id = 0\n",
    "        self.pad_token_id = 1\n",
    "        self.sep_token_id = 2\n",
    "        \n",
    "        self.pad_token = '<pad>'\n",
    "        self.cls_token = '<s>'\n",
    "        self.sep_token = '</s>'\n",
    "        \n",
    "    def bpe_encode(self,text):\n",
    "        return self.bpe.encode(text)\n",
    "    \n",
    "    def encode(self,text,add_special_tokens=False):\n",
    "        subwords = self.bpe.encode(text)\n",
    "        input_ids = self.vocab.encode_line(subwords, append_eos=False, add_if_not_exist=False).long().tolist()\n",
    "        return input_ids\n",
    "    \n",
    "    def tokenize(self,text):\n",
    "        return self.bpe_encode(text).split()\n",
    "    \n",
    "    def convert_tokens_to_ids(self,tokens):\n",
    "        input_ids = self.vocab.encode_line(' '.join(tokens), append_eos=False, add_if_not_exist=False).long().tolist()\n",
    "        return input_ids\n",
    "    \n",
    "    #from: https://www.kaggle.com/nandhuelan/bertweet-first-look\n",
    "    def decode_id(self,id):\n",
    "        return self.vocab.string(id, bpe_symbol = '@@')\n",
    "    \n",
    "    def decode_id_nospace(self,id):\n",
    "        return self.vocab.string(id, bpe_symbol = '@@ ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BERTweetTokenizer('/kaggle/input/bertweet-base-transformers')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "92f44b1c3a5e9a59a46c4705ba8cdd4d73408c72603eb7b15f7b3da805ee7ccf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
